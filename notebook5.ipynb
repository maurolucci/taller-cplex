{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829595d6",
   "metadata": {},
   "source": [
    "# Notæ 5\n",
    "\n",
    "# Automatización de pruebas computacionales\n",
    "\n",
    "En los notebooks anteriores vimos los fundamentos para generar grafos con el paquete NetworkX, modelar con PLE problemas de optimización en grafos, escribir estos modelos en Python, resolverlos con CPLEX y consultar las soluciones encontradas. Sin embargo, todo este proceso fue bastante \"manual\", en el sentido que tuvimos que \"tocar\" bastante código en todo lo que fuimos haciendo. El objetivo de este notebook es aprender buenas prácticas para automatizar este proceso. \n",
    "\n",
    "Primero, aprenderemos a crear un dataset, es decir, un directorio que contenga un archivo por cada instancia que estemos interesados en resolver, con algún formato en particular. Segundo, aprenderemos a leer estos archivos, volver a convertirlos en valores que puedan ser interpretados por Python, para luego poder escribir sus correspondientes modelos de PLE y resolverlos. Buscamos que esto último sea independiente del dataset, es decir, que el dataset sea un argumento de entrada a nuestro programa. Tercero, aprenderemos a guardar las salidas de CPLEX en archivos. De esta forma, podemos dejar corriendo pruebas durante horas o días y, al finalizar, podemos revisar los archivos generados y analizar las salidas producidas.\n",
    "\n",
    "Este proceso será ejemplificado siguiendo como caso de estudio el Problema de Dominación Generalizado (más adelante veremos su definición formal). Dado que este problema es difícil en grafos bipartitos y split, nos parece interesante poder incluir en el dataset instancias con grafos de estas clases. Por lo tanto, antes de empezar a crear el dataset, continuaremos ampliando los contenidos del notebook 4 y aprenderemos a generar algunas clases de grafos nuevas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95490f",
   "metadata": {},
   "source": [
    "## Generación avanzada de grafos (continuación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3b604",
   "metadata": {},
   "source": [
    "En primer lugar, vamos a necesitar todos los generadores de grafos que definimos en el notebook 4. Si bien podríamos copiar todas las definiciones acá, vamos a seguir un enfoque diferente para que el notebook no quede demasiado largo. Ya nos tomamos el trabajo de pasar todas estas definiciones a un archivo <code>generadores.py</code> que lo pueden descargar del siguiente  <a href=\"https://github.com/maurolucci/taller-cplex/blob/main/generadores.py\">link</a>. <b>Guarden este archivo en el mismo directorio donde está este notebook</b> (si siguieron las intrucciones, debería ser en el directorio Taller/). \n",
    "\n",
    "Una vez hecho esto, ya podemos importar este archivo, así las funciones allí definidas pueden ser usadas en este notebook. En en este caso, en la importación optamos por ponerle un nombre abreviado <code>gen</code> (como hicimos con networkx y nx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a49854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generadores as gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b3b1c",
   "metadata": {},
   "source": [
    "Por ejemplo, podemos generar el grafo de kneser K(5,2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85560f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "petersen = gen.generar_kneser(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6784a77",
   "metadata": {},
   "source": [
    "También vamos a importar el módulo NetworkX, para tener a disposición sus generadores y funciones built-in. Y también necesitaremos el módulo <code>random</code> (ya veremos para qué)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432dc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ea8da",
   "metadata": {},
   "source": [
    "### Grafos bipartitos aleatorios\n",
    "\n",
    "<b>Definición.</b> Un grafo $G=(V,E)$ es bipartito si $V$ se puede particionar en dos conjuntos $A$ y $B$, es decir, $V = A \\cup B$ y $A \\cap B = \\emptyset$, tales que toda arista conecta un vértice de un conjunto con un vértice del otro, es decir, para todos $a_1,a_2 \\in A$ y $b_1,b_2 \\in B$, se tiene $a_1a_2, b_1b_2 \\not\\in E$.\n",
    "\n",
    "La generación de un grafo bipartito aleatorio $G=(A \\cup B, E)$ se puede realizar por medio de los siguientes parámetros:\n",
    "* Un número natural $nA$ que representa el cardinal de $A$ (primer conjunto de la bipartición).\n",
    "* Un número natural $nB$ que representa el cardinal de $B$ (segundo conjunto de la bipartición).\n",
    "* Un número real $p \\in [0,1]$ que representa la probabilidad de que un vértice de $A$ y uno de $B$ sean adyacentes.\n",
    "\n",
    "La idea de la generación es la siguiente. Recorremos cada par de vértices $(a,b)$ con $a \\in A$ y $b \\in B$ y decidimos si agregamos una arista entre $a$ y $b$ de forma aleatoria. Para ello, generamos un número flotante aleatorio en $[0,1]$ con una distribución uniforme mediante la función <code>random</code> del módulo <code>random</code>. Si el número aleatorio generado es menor a $p$ entonces agregamos la arista. El único cuidado que tenemos que tener es no pisar el nombre de los vértices de $A$ con los de $B$. Por este motivo, etiquetamos a los vértices de $A$ como $\\{0,1,\\ldots,nA-1\\}$ y a los de $B$ como $\\{nA,nA+1,\\ldots,nB-1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_bipartito_aleatorio(nA,nB,p):\n",
    "    G = nx.Graph()\n",
    "    # Aristas entre A y B\n",
    "    for a in range(nA):\n",
    "        for b in range(nB):\n",
    "            if random.random() < p: # Agregamos arista?\n",
    "                G.add_edge(a, nA+b)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cdead",
   "metadata": {},
   "source": [
    "Probamos nuestra función y graficamos el grafo resultante. Aprovechamos que NetworkX nos provee la función <code>bipartite_layout(G, A)</code> que nos computa un lindo layout para los vértices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nA = 5\n",
    "nB = 10\n",
    "p = 0.5\n",
    "G = generar_bipartito_aleatorio(nA, nB, p)\n",
    "nx.draw_networkx(G, pos=nx.bipartite_layout(G, range(nA)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935e453",
   "metadata": {},
   "source": [
    "### Grafos split aleatorios\n",
    "\n",
    "<b>Definición.</b> Un grafo $G=(V,E)$ es split si $V$ se puede particionar en una clique $K$ y un estable $S$.\n",
    "\n",
    "La generación de un grafo split aleatorio $G=(K \\cup S, E)$ se puede realizar de una forma muy similar a la anterior. Consideraremos los siguientes parámetros:\n",
    "* Un número natural $nK$ que representa el cardinal de $K$ (clique).\n",
    "* Un número natural $nS$ que representa el cardinal de $S$ (estable).\n",
    "* Un número real $p \\in [0,1]$ que representa la probabilidad de que un vértice de $K$ y uno de $S$ sean adyacentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ad539",
   "metadata": {},
   "source": [
    "### &#x1f4bb; Actividad 1. \n",
    "\n",
    "Completar la definición de la siguiente función que genera un grafo split aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Espacio para completar la Actividad 1\n",
    "\n",
    "def generar_split_aleatorio(nK,nS,p):\n",
    "    G = nx.Graph()\n",
    "    # COMPLETAR\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39248c0b",
   "metadata": {},
   "source": [
    "### Grafos webs\n",
    "\n",
    "Queremos hacer un comentario repecto a los grafos webs antes de pasar a armar el dataset. Repasemos su definición.\n",
    "\n",
    "<b>Definición.</b> Dados $n,m \\in \\mathbb{N}$ con $n \\leq 2m+1$, el grafo web $W^m_n$ es un grafo donde $V(W^m_n) = \\{v_0,\\ldots,v_{n-1}\\}$ y $v_iv_j \\in E(W^m_n)$ si y solo si $j \\equiv i \\pm l\\ (mod\\ n)$, $l \\in \\{1,\\ldots,m\\}$.\n",
    "\n",
    "También es sabido que $W^m_n$ es isomorfo a $(C_n)^m$, es decir, a la $m$-ésima potencia del ciclo $C_n$. \n",
    "\n",
    "El módulo NetworkX ya nos provee la función <code>power(G, k)</code> que permite calcular la $k$-ésima potencia de un grafo $G$. Por lo tanto la generación de grafos webs es trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2961219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_web(n,m):\n",
    "    return nx.power(nx.cycle_graph(n),m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad409c",
   "metadata": {},
   "source": [
    "Ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_10_2 = generar_web(10,2)\n",
    "nx.draw_networkx(W_10_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa47e9",
   "metadata": {},
   "source": [
    "## Caso de estudio\n",
    "\n",
    "<b>Definición.</b> Dado un grafo $G=(V,E)$ y dos vectores $k,u \\in \\mathbb{Z}_+^V$, una función de $(k,u)$-dominación de $G$ es una función $f: V \\to \\mathbb{Z}_+$ tal que, para todo $v \\in V$, $f(v) \\leq u_v$ y $f(N[v]) \\doteq \\sum_{w \\in N[v]}f(w) \\geq k_v$. \n",
    "\n",
    "Vamos a trabajar con el siguente problema.\n",
    "\n",
    "<b>Problema de Dominación Generalizado (PDG)</b>.<br>\n",
    "<b>Entrada.</b> Un grafo $G=(V,E)$ y dos vectores $k,u \\in \\mathbb{Z}_+^V$.<br>\n",
    "<b>Objetivo.</b> Encontrar una función $f$ de $(k,u)$-dominación de $G$ con mínimo $f(V) \\doteq \\sum_{v \\in V}f(v)$.\n",
    "\n",
    "Este problema generaliza a muchos problemas de dominación. En particular generaliza a la dominación clásica cuando $u = k = \\boldsymbol{1}$.\n",
    "\n",
    "De forma análoga se puede definir el Problema de Packing Generalizado, más detalles consultar en  <a href=\"https://www.sciencedirect.com/science/article/pii/S1877050923010220\">E. Hinrichsen, G. Nasini, N. Vansteenkiste (2023)</a>. Es interesante mencionar que estos dos problemas son \"equivalentes\", en el sentido de que una entrada de uno se puede transformar en tiempo polinomial en una entrada del otro, y viceversa. Actualmente las autoras se encuentran estudiando estos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e9b70",
   "metadata": {},
   "source": [
    "Una formulación de PLE intuitiva para este problema es la siguiente.\n",
    "\n",
    "\\begin{align*}\n",
    "\\min & \\sum_{v \\in V} f_v & \\\\\n",
    "s.a.\\ & \\sum_{w \\in N[v]} f_w \\geq k_v & \\forall\\ v \\in V.\\tag{1}\\\\\n",
    "& f_v \\leq u_v & \\forall\\ v \\in V.\\tag{2}\\\\ \n",
    "& f_v \\in \\mathbb{Z}_+ & \\forall\\ v \\in V.\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4106ad1",
   "metadata": {},
   "source": [
    "En Python podemos escribir fácilmente una función que construya y resuelva este modelo. Pero primero importamos los módulos de CPLEX que vamos a necesitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "from docplex.mp.solution import SolveSolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764d59e",
   "metadata": {},
   "source": [
    "Para definir la función, se tienen en cuenta las siguientes consideraciones. \n",
    "* Se considera un argumento por cada entrada de PDG. En particular, se elegió representar los vectores $k$ y $u$ con listas de Python. \n",
    "* Se agrega un argumento opcional <code>archivo</code> a la función (con un valor <code>None</code> por defecto). Más adelante volveremos a este punto. Por lo pronto, adelantamos que lo usaremos para que CPLEX escriba el log en ese archivo.\n",
    "* Las variables enteras las agregamos con el método <code>integer_var</code> de la clase <code>Model</code>, que toma como argumento una cota inferior para la variable, una cota superior y el nombre de la variable. Estas cotas hacen que las restricciones (2) puedan ser deducidas por CPLEX y no necesiten ser agregadas al modelo.\n",
    "* Retornamos el modelo y la solución de CPLEX. Más adelante aprenderemos a manipularlos adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1547e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolver_PDG(G, k, u, archivo=None):\n",
    "    \"\"\"Construye y resuelve el modelo de PLE para el PDG.\"\"\"\n",
    "    \n",
    "    # Inicializamos el modelo \n",
    "    modelo = Model(name='dom-gen') \n",
    "    \n",
    "    # Variables\n",
    "    F = [modelo.integer_var(0, u[v], 'f_' + str(v)) for v in G]\n",
    "    \n",
    "    # Funcion objetivo\n",
    "    modelo.minimize(modelo.sum(F[v] for v in G))\n",
    "    \n",
    "    # Restricciones (1)\n",
    "    # Recordar que G.neighbors(v) es la vecindad abierta de v\n",
    "    for v in G:\n",
    "        modelo.add_constraint(F[v] + modelo.sum(F[w] for w in G.neighbors(v)) >= k[v])\n",
    "\n",
    "    # Resolvemos el modelo\n",
    "    sol = modelo.solve(log_output=archivo)\n",
    " \n",
    "    # Retornamos la solucion\n",
    "    return modelo, sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479da35",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta sección aprenderemos a crear un dataset. La pregunta más importante que tenemos que hacer antes de arrancar es: ¿cuáles instancias nos interesa resolver? Por supuesto que la respuesta dependerá de lo que estemos estudiando. \n",
    "\n",
    "Recordar que una instancia de PDG se compone de: \n",
    "1. Un grafo $G$.\n",
    "2. Vectores $k$ y $u$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1fa35",
   "metadata": {},
   "source": [
    "#### 1. Grafo de entrada\n",
    "\n",
    "En nuestro caso, vamos a generar algunos grafos aleatorios de Erdős-Rényi, bipartitos aleatorios, split aleatorios, arco circulares aleatorios y webs. Usaremos como parámetros para la generación algunos valores que nos parecieron razonable, los cuales se mencionan a continuación, pero como hemos mencionado esto siempre dependerá del tipo de experimento.\n",
    "\n",
    "* Para cada combinación de $n = 150$ y $p \\in \\{0.25,0.5,0.75\\}$, hay una instancia con un grafo de Erdős-Rényi (aleatorio) con parámetros $n$ (número de vértices) y $p$ (probabilidad de arco). \n",
    "Cuando hay azar involucrado, siempre es recomendable generar varios grafos para cada combinación de parámetros. En nuestro caso, generamos 3 grafos diferentes por cada combinación. Luego, para cada $i \\in \\{1,2,3\\}$, llamamos a estas instancias <code>erdos-renyi_n_p_i</code>, es decir, tenemos las siguientes:\n",
    "    * <code>erdos-renyi_150_0.25_1</code>\n",
    "    * <code>erdos-renyi_150_0.25_2</code>\n",
    "    * <code>erdos-renyi_150_0.25_3</code>\n",
    "    * <code>erdos-renyi_150_0.5_1</code>\n",
    "    * <code>erdos-renyi_150_0.5_2</code>\n",
    "    * <code>erdos-renyi_150_0.5_3</code>\n",
    "    * <code>erdos-renyi_150_0.75_1</code>\n",
    "    * <code>erdos-renyi_150_0.75_2</code>\n",
    "    * <code>erdos-renyi_150_0.75_3</code>\n",
    "* Para cada combinación de $nA = 100$, $nB = 50$, $p \\in \\{0.25,0.5,0.75\\}$ e $i \\in \\{1,2,3\\}$, hay una instancia con un grafo bipartito aleatorio con parámetros $nA, nB, p$, de nombre <code>bipartito_aleatorio_nA_nB_p_i</code>.\n",
    "* Para cada combinación de $nK = nS = 100$, $p \\in \\{0.25,0.5,0.75\\}$ e $i \\in \\{1,2,3\\}$, hay una instancia con un grafo split aleatorio con parámetros $nk,nS,p$, de nombre <code>bipartito_aleatorio_nK_nS_p_i</code>. \n",
    "* Para cada combinación de $n = 200$, $i = 2$, $f = \\{0.5,1,2\\}$ y $j \\in \\{1,2,3\\}$, hay una instancia con un grafo arco circular aleatorio con parámetros $n,i,f$, de nombre <code>arco_cicular_aleatorio_n_i_f_j</code>.\n",
    "* Para cada combinación de $n = 200$ y $m = \\{5,10,15,20\\}$, hay una instancia con un grafo web con parámetros $n,m$, de nombre <code>web_n_m</code>. Dado que no hay aleatoriedad en su generación, basta con generar una instancia por cada combinación de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b9e05",
   "metadata": {},
   "source": [
    "#### 2. Vectores de entrada\n",
    "\n",
    "Respecto a los vectores, no estamos interesados a priori en ningún valor en particular, por lo tanto vamos a generarlos también de forma aleatoria. Por supuesto, no tiene que ser siempre así, por ejemplo podríamos estar interesados en el caso particular $k = u = \\boldsymbol{1}$ (dominación clásica).\n",
    "\n",
    "Para esto, será de utilidad definir una función <code>generar_vector_aleatorio(n,i,f)</code>, que dados tres naturales $n,i,f$ tales que $i \\leq f$, retorne un vector de largo $n$ donde cada componente es un número aleatorio en el conjunto $\\{i,...,f\\}$. En particular, representaremos al vector con una lista de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523201bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_vector_aleatorio(n,i,f):\n",
    "    return [random.randint(i,f) for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402f485",
   "metadata": {},
   "source": [
    "Entonces por ejemplo, podemos generar el siguiente vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generar_vector_aleatorio(10,2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d28f4",
   "metadata": {},
   "source": [
    "Para todos los grafos, usaremos un vector $k$ con números aleatorios en el conjunto $\\{1,2,3\\}$ y un vector $u$ con números aleatorios en el conjunto $\\{0,1,2,3,4,5\\}$. Es decir, todos los grafos tendrán vectores $k$ y $u$ diferentes, pero generados con los mismos parámetros. \n",
    "\n",
    "<b>Observación.</b> El PDG puede tener instancias infactibles. Por ejemplo, si existe un vértice $v$, tal que $u_v = u_w = 1$ para todo $w$ vecino de $v$, pero $k_v > |N[v]|$. \n",
    "\n",
    "A priori, la generación que propusimos no garantiza que esto no ocurra. De todas formas, esto no será un problema y todo el código del notebook manejará sin problema estos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e40f4b",
   "metadata": {},
   "source": [
    "### Leer y escribir instancias\n",
    "\n",
    "Generalmente, es útil guardar (escribir) las instancias en archivos luego de generarlas. En particular, esto se vuelve imprescindible cuando hay azar involucrado en la generación. Si no lo hacemos, nos será casi imposible volver a generar exactamente la misma instancia (por la aleatoriedad de la generación). Al guardar las instancias en un archivo, podemos repetir las pruebas computacionales tantas veces como querramos sobre las mismas entradas. Obviamente, también debemos ser capaces de poder leer esos archivos y recuperar las instancias.\n",
    "\n",
    "Para cada instancia, por ejemplo <code>erdos-renyi_150_0.25_1</code>, vamos a guardar tres archivos:\n",
    "* <code>erdos-renyi_150_0.25_1.graph</code> guardará el grafo $G$.\n",
    "* <code>erdos-renyi_150_0.25_1.list.k</code> guardará el vector $k$.\n",
    "* <code>erdos-renyi_150_0.25_1.list.u</code> guardará el vector $u$.\n",
    "\n",
    "Todos estos archivos los guardaremos en un directorio de nombre <code>dataset/</code> (dentro del directorio <code>Taller/</code>). \n",
    "\n",
    "Podemos crear este directorio directamente desde Python. Una forma de hacerlo es importar el módulo <code>os</code>. Este módulo nos provee la función <code>mkdir</code> para crear un directorio. Si bien podemos llamar directamente a esta función, nos gustaría evitar que se ejecute si el directorio ya existía (por ejemplo, si volvemos a ejecutar la celda). Para eso usamos la estructura de control <code>try/except</code> de Python. De esta forma, Python intentará crear el directorio y si ocurre una excepción (error), entonces no se interrumpirá la ejecución, sino que seguirá ejecutando el bloque except (en este caso, con un <code>pass</code> que es una sentencia vacía, es decir, Python no hará nada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292466ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"dataset\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1e1ea",
   "metadata": {},
   "source": [
    "Antes de guardar los archivos, <b>es necesario definir un formato para los mismos</b>. Nosotros vamos a convenir lo siguiente (nuevamente esto es a libre elección de cada uno/una).\n",
    "\n",
    "* El grafo se almecenará en formato <a href=\"https://users.cecs.anu.edu.au/~bdm/data/formats.html\">graph6 y sparse6</a>, específicamente diseñado para comprimir el grafo y reducir el peso del archivo. Por suerte, el módulo NetworkX nos provee las funciones <code>write_graph6(G,ruta)</code> y <code>read_graph6(ruta)</code> para escribir y leer este formato.\n",
    "* Los vectores (listas de Python) los guardaremos como una cadenas de caracteres (texto). Así por ejemplo, la lista <code>[1,2,3]</code> se guardará como el texto \"[1,2,3]\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1fe9d",
   "metadata": {},
   "source": [
    "Aunque la implementación de las funciones que leen y escriben instancias con estos formatos no son complicadas (unas pocas líneas de código), decidimos separarlas de este notebook para evitar que quede demasiado extenso. Por lo tanto, en este punto es necesario descargar el archivo de nombre <code>instancia.py</code> del siguiente  <a href=\"https://github.com/maurolucci/taller-cplex/blob/main/instancia.py\">link</a> y guardarlo en el mismo directorio donde está este notebook.\n",
    "\n",
    "A continuación, lo importamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbe8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3b8e8",
   "metadata": {},
   "source": [
    "Aquellos que sientan curiosidad, pueden revisar el archivo para ver como están definidas las funciones. Sino lo único que necesitamos saber es que contamos con las siguientes:\n",
    "* <code>escribir_instancia(G, k, u, ruta)</code> escribe la instancia que recibe como argumento en la ruta especificada.\n",
    "* <code>leer_instancia(ruta)</code> lee la instancia de la ruta especificada y la retorna (en forma de tupla con el grafo y los vectores).\n",
    "\n",
    "<b>Observación.</b> La ruta debe ser una cadena de caracteres sin la extensión del archivo, por ejemplo <code>dataset/erdos-renyi_150_0.25_1</code> sin el <code>.graph</code>, <code>.list.k</code> o <code>.list.u</code>. La extensión la maneja la propia función."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9899c",
   "metadata": {},
   "source": [
    "Ahora estamos listos para crear nuestro dataset. Aunque esta parte del código no es difícil, se vuelve un poco tediosa porque tenemos que generar cada una de clases de grafos que habíamos mencionado, con sus respectivos parámetros y nombres, y escribirlas en los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc762481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_dataset():\n",
    "    \n",
    "    # Grafos Erdős-Rényi\n",
    "    n = 150\n",
    "    for p in [0.25, 0.5, 0.75]:\n",
    "        for i in [1, 2, 3]:\n",
    "            G = nx.erdos_renyi_graph(n, p)\n",
    "            ruta = \"dataset/erdos-renyi_\" + str(n) + \"_\" + str(p) + \"_\" + str(i)\n",
    "            k = generar_vector_aleatorio(G.number_of_nodes(), 1, 3)\n",
    "            u = generar_vector_aleatorio(G.number_of_nodes(), 0, 5)\n",
    "            instancia.escribir_instancia(G, k, u, ruta)\n",
    "    \n",
    "    # Grafos bipartitos aleatorios\n",
    "    nA = 100\n",
    "    nB = 50\n",
    "    for p in [0.25, 0.5, 0.75]:\n",
    "        for i in [1, 2, 3]:\n",
    "            G = generar_bipartito_aleatorio(nA, nB, p)\n",
    "            ruta = \"dataset/bipartito_aleatorio_\" + str(nA) + \"_\" + str(nB) + \"_\" + str(p) + \"_\" + str(i)\n",
    "            k = generar_vector_aleatorio(G.number_of_nodes(), 1, 3)\n",
    "            u = generar_vector_aleatorio(G.number_of_nodes(), 0, 5)\n",
    "            instancia.escribir_instancia(G, k, u, ruta)\n",
    "\n",
    "    # Grafos split aleatorios\n",
    "    # COMPLETAR\n",
    "    \n",
    "    # Grafos arco circulares aleatorios\n",
    "    n = 200\n",
    "    i = 2\n",
    "    for f in [0.5, 1, 2]:\n",
    "        for j in [1, 2, 3]:\n",
    "            G = gen.generar_arco_circular_aleatorio(n, i, f)\n",
    "            ruta = \"dataset/arco_circular_\" + str(n) + \"_\" + str(i) + \"_\" + str(f) + \"_\" + str(j)\n",
    "            k = generar_vector_aleatorio(G.number_of_nodes(), 1, 3)\n",
    "            u = generar_vector_aleatorio(G.number_of_nodes(), 0, 5)\n",
    "            instancia.escribir_instancia(G, k, u, ruta)\n",
    "\n",
    "    # Grafos webs\n",
    "    n = 200\n",
    "    for m in [5, 10, 15, 20]:\n",
    "        G = generar_web(n, m)\n",
    "        ruta = \"dataset/web_\" + str(n) + \"_\" + str(m)\n",
    "        k = generar_vector_aleatorio(G.number_of_nodes(), 1, 3)\n",
    "        u = generar_vector_aleatorio(G.number_of_nodes(), 0, 5)\n",
    "        instancia.escribir_instancia(G, k, u, ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c4726",
   "metadata": {},
   "source": [
    "Luego llamamos a esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70eb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff1962",
   "metadata": {},
   "source": [
    "Al finalizar, podemos ir a ver el directorio <code>dataset/</code> y deberíamos encontrar todas las instancias generadas. También podemos hacerlo desde Python mediante la función <code>glob</code> del módulo <code>glob</code>, que toma como argumento el nombre del archivo que queremos buscar (el asterístico quiere decir que buscamos todos) y la ruta del directorio donde queremos buscar. Puede ser que esta función no ande en Python 3.9 o anterior (si alguien tiene algún problema nos puede contactar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d747cec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "glob.glob(\"*\", root_dir=\"dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f4613",
   "metadata": {},
   "source": [
    "Incluso podemos ordenar la lista alfabéticamente con la función <code>sorted</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9b477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(glob.glob(\"*\", root_dir=\"dataset/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85800abe",
   "metadata": {},
   "source": [
    "### &#x1f4bb; Actividad 2. \n",
    "\n",
    "Modificar la definición de la función <code>generar_dataset</code> de modo que también genere grafos split aleatorios con los criterios mencionados: Para cada combinación de $nK = nS = 100$, $p \\in \\{0.25,0.5,0.75\\}$ e $i \\in \\{1,2,3\\}$, hay una instancia con un grafo split aleatorio con parámetros $nk,nS,p$, de nombre <code>bipartito_aleatorio_nK_nS_p_i</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Espacio para completar la Actividad 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60dd3e5",
   "metadata": {},
   "source": [
    "Luego, volver a generar el dataset para que aparezcan esas instancias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e5be6",
   "metadata": {},
   "source": [
    "## Ejecución\n",
    "\n",
    "En este punto, ya tenemos el dataset creado y estamos listos para resolver el PDG sobre las instancias del dataset.\n",
    "\n",
    "Para una mejor organización, vamos crear un directorio <code>exp1/</code> donde vamos a guardar todo lo referido a este primer experimento computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"exp1\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e8fba",
   "metadata": {},
   "source": [
    "Ahora tenemos que escribir una función <code>ejecutar_exp1</code>, que tome por argumentos la ruta del directorio donde estan las instancias y la ruta del directorio donde guardar los resultados de este experimento, y se ocupe de iterar sobre los archivos, leer las instancias, resolver el PDG sobre ellas y escribir las salidas en archivos. \n",
    "\n",
    "Para cada instancia, por ejemplo <code>erdos-renyi_150_0.25_1</code>, la salida de CPLEX la vamos a escribir en un archivo de nombre <code>erdos-renyi_150_0.25_1.log</code> en el directorio <code>exp1/</code>. En Python para poder escribir en un archivo, primeramente es necesario abrirlo. Esto se hace de la siguiente forma:\n",
    "\n",
    "<code>with open(ruta,\"w\") as descriptor:\n",
    "        # Más codigo</code>\n",
    "\n",
    "Con esas líneas llamamos a la función <code>open</code> de Python que se ocupa de abrir el archivo de nombre <code>ruta</code> en modo escritura (para abrirlo en modo lectura se usa \"r\"), creándolo en caso de que no exista. Como resultado, devuelve un descriptor de archivo (que contiene mucha información, por ejemplo la posición en donde debe escribir, la cual va cambiando a medida que escribimos). Este descriptor es precisamente lo que toma el cuarto argumento que incluímos en la función <code>resolver_PDG</code>. Es decir, que el log de CPLEX se escribirá en ese archivo. Al finalizar el bloque <code>with</code>, el mismo Python se ocupará de cerrar el archivo.\n",
    "\n",
    "El siguiente código se ocupa de esto, incluímos comentarios para facilitar su lectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_exp1(dir_instancias, dir_experimento):\n",
    "    # Recorremos las instancias\n",
    "    for ruta in sorted(glob.glob(\"*.graph\", root_dir=dir_instancias)):\n",
    "        # Nos quedamos con el nombre de la instancia sin el .graph\n",
    "        # Recordar que si tenemos una lista de nombre l, \n",
    "        # hacer l[:-n] se queda con la sublista sin los últimos n elementos \n",
    "        ruta = ruta[:-6] \n",
    "        # Leemos la instancia\n",
    "        G, k, u = instancia.leer_instancia(dir_instancias + ruta) \n",
    "        # Creamos y abrimos el archivo para guardar el log de CPLEX\n",
    "        with open(dir_experimento + ruta + \".log\",\"w\") as log:\n",
    "            # Resolvemos\n",
    "            modelo, sol = resolver_PDG(G, k, u, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ead70a",
   "metadata": {},
   "source": [
    "Listo, solo nos queda llamar a esta función (puede demorar unos minutos, momento para unos \t&#129481;\t&#129481;\t&#129481;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutar_exp1(\"dataset/\", \"exp1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e879999",
   "metadata": {},
   "source": [
    "Podemos ir a revisar este directorio y ver los logs a mano. También podemos verlos por acá, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp1/bipartito_aleatorio_100_50_0.25_1.log\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf88e8",
   "metadata": {},
   "source": [
    "Si bien con estos fundamentos ya podemos automatizar nuestras pruebas, de una forma ordenada y sistemática, seguiremos avanzando un poco más... Vamos a incoporar algunos mecanismos que serán de mucha utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b3ce2",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "En el notebook 3 mencionamos la importancia y los benefecios de hacer testing. Por lo tanto, vamos a escribir funciones que interpreten la salida de CPLEX, recuperen la función de $(k,u)$-dominación de $G$ y verifiquen que efectivamente lo sea.\n",
    "\n",
    "Vamos a representar a las funciones de $(k,u)$-dominación con diccionarios de Python (de la misma forma que hicimos con los coloreos).  \n",
    "\n",
    "Recordemos que la función <code>resolver_PDG</code> que escribimos al principio de este notebook retornaba la solución encontrada por CPLEX. Esta solución es un objeto de la clase <code>SolveSolution</code> que tiene diversos métodos con las cuales podremos manipularla. Por ejemplo, tiene el método <code>get_value</code>, que toma el nombre de una variable y devuelve el valor de esa variable en la solución encontrada. Obviamente, necesitamos convertir ese valor a un número entero, y para ello vamos a aprovechar la función <code>round</code> de Python que se ocupa de redondear un número flotante al entero más cercano. \n",
    "\n",
    "Por lo tanto, vamos a definir una función <code>obtener_func_dom</code> que tome un grafo y una solución, y retorne el diccionario que representa a la función de $(k,u)$-dominación del grafo encontrada por CPLEX. Este diccionario lo escribimos por comprensión (como ya hemos escrito anteriormente listas, restricciones, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ac376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_func_dom(G, sol):\n",
    "    return {v : round(sol.get_value(\"f_\" + str(v))) for v in G}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1f596",
   "metadata": {},
   "source": [
    "Probemos nuestra función, por ejemplo para resolver el problema de dominación clásica sobre un ciclo de 5 vértices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C5 = nx.cycle_graph(5)\n",
    "k = [1] * 5 # Lista con cinco 1s\n",
    "u = [1] * 5 # Lista con cinco 1s\n",
    "_, sol = resolver_PDG(C5, k, u) \n",
    "f = obtener_func_dom(C5, sol)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8367d67",
   "metadata": {},
   "source": [
    "Ahora podemos, verificar que este diccionario represente en efecto una función $f$ de $(k,u)$-dominación. Es decir, para todo vértice v, se debe verificar $f(v) \\leq u_v$ y $f(N[v]) \\geq k_v$. Esto en Python podemos hacerlo con la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_func_dom(G, k, u, f):\n",
    "    for v in G:\n",
    "        if f[v] < 0 or f[v] > u[v]: # Control 0 <= f(v) <= u_v\n",
    "            return False\n",
    "        suma = f[v] # Acumulador de f(N[v])\n",
    "        for w in G.neighbors(v):\n",
    "            suma += f[w]\n",
    "        if suma < k[v]: # Control f(N[v]) >= k_v\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648877d",
   "metadata": {},
   "source": [
    "Por ejemplo, corroboramos que el diccionario de arriba sea una función de $(\\boldsymbol{1},\\boldsymbol{1})$-dominación de $C_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_func_dom(C5, k, u, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe98dd",
   "metadata": {},
   "source": [
    "Y por el contrario, el siguiente diccionario no lo es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {0: 0, 1: 0, 2: 0, 3: 0, 4: 1}\n",
    "es_func_dom(C5, k, u, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf2b05",
   "metadata": {},
   "source": [
    "Ya podemos incorporar este testing a nuestra función que ejecuta los experimentos. Para ello, partimos de la definición original y al final agregamos algunas líneas de código nuevas. \n",
    "\n",
    "Primero, recuperamos la función de dominación llamado a <code>obtener_func_dom</code>, lo que nos devuelve un dicionario. Luego llamamos a <code>es_func_dom</code> para hacer el testing, por medio de la directiva assert (recordar que en caso de que <code>es_func_dom</code> retorne <code>False</code>, la directiva assert interrumpe la ejecución y muestra el mensaje de error en la pantalla; de lo contrario el programa continua). \n",
    "\n",
    "Vamos a aprovechar además para escribir la función de dominación en un archivo. Para cada instancia, por ejemplo <code>erdos-renyi_150_0.25_1</code>, escribiremos el diccionario en un archivo de nombre <code>exp1/erdos-renyi_150_0.25_1.sol</code>. \n",
    "\n",
    "Al igual que hicimos con las listas (que representaban a los vectores $k$ y $u$), también almacenaremos los diccionarios como cadenas de caracteres. El módulo <code>instancia</code> ya provee las funciones <code>escribir_diccionario(diccionario, ruta)</code> y <code>leer_diccionario(ruta)</code>, para leer y escribir diccionarios en archivos. \n",
    "\n",
    "En caso de no encontrar solución, escribiremos un diccionario vacío.\n",
    "\n",
    "Luego, el código queda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_exp1(dir_instancias, dir_experimento):\n",
    "    # Recorremos las instancias\n",
    "    for ruta in sorted(glob.glob(\"*.graph\", root_dir=dir_instancias)):\n",
    "        # Nos quedamos con el nombre de la instancia sin el .graph\n",
    "        ruta = ruta[:-len(\".graph\")] \n",
    "        # Leemos la instancia\n",
    "        G, k, u = leer_instancia(dir_instancias + ruta) \n",
    "        # Creamos y abrimos el archivo para guardar el log de CPLEX\n",
    "        with open(dir_experimento + ruta + \".log\", \"w\") as log:\n",
    "            # Resolvemos\n",
    "             modelo, sol = resolver_PDG(G, k, u, log) \n",
    "        \n",
    "        # Procesamos la solución\n",
    "        if sol: # Si encontró solución\n",
    "            # Recuperamos la función de dominación\n",
    "            f = obtener_func_dom(G, sol)\n",
    "            assert es_func_dom(G, k, u, f), \"Error: No es funcion de dominacion\"\n",
    "            # Escribimos la funcion de dominacion\n",
    "            instancia.escribir_diccionario(f, dir_experimento + ruta + \".sol\")\n",
    "        else: # Si no encontró solución\n",
    "            instancia.escribir_diccionario(dict(), dir_experimento + ruta + \".sol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e80d39",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "Una incorporación muy útil para nuestro programa es escribir en un archivo un resumen con los resultados obtenidos para cada instancia. El objetivo es posteriormente poder acceder rápidamente a estos valores y simplificar su análisis.\n",
    "\n",
    "Para esto, tenemos que definir qué valores nos interesa reportar en el resumen. En nuestro caso, vamos a escribir, por cada instancia, una línea con los siguientes valores separados por coma (en caso de necesitar más/menos cosas se puede modificar):\n",
    "\n",
    "<code>nombre de la instancia, número de vértices, número de aristas, densidad de grafo, número de variables, número de restricciones, estado de la solución, cota inf, cota sup, gap, tiempo de ejecución</code>\n",
    "\n",
    "El archivo con el resumen tendrá de nombre <code>resumen.csv</code> y se ubicará el directorio <code>exp1/</code>. Al comienzo de la función, revisamos si el archivo ya existía, de lo contrario lo creamos y escribimos la primer linea con el nombre de las columnas.\n",
    "\n",
    "Usamos la función <code>print</code> de Python para escribir el resumen, con la salvedad de que vamos a indicarle con el argumento <code>file=</code> el descriptor del archivo donde queremos escribir y con <code>sep=</code> la cadena con la que queremos que separe a cada valor a imprimir (en nuestro caso es una coma). \n",
    "\n",
    "Luego, cada vez que terminamos de resolver una instancia, volvemos a abrir el resumen y agregamos una nueva línea con el resumen. Esta vez, abrimos el archivo en un modo especial de escritura (\"a\"), que permite escribir al final del archivo, manteniendo todo su contenido anterior intacto.\n",
    "\n",
    "Como última aclaración, CPLEX solo permite consultar por el valor objetivo siempre que haya encontrado al menos una solución. Por lo tanto, en caso de que no haya encontrado ninguna (por ejemplo si la instancia es infactible), vamos a convenir en escribir un -1.\n",
    "\n",
    "Entonces, redefinimos la función <code>ejecutar_exp1</code> de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e34774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_exp1(dir_instancias, dir_experimento):\n",
    "    \n",
    "    # Si no existe el archivo de resumen, lo creamos y\n",
    "    # escribimos el nombre de las columnas\n",
    "    if not glob.glob(\"resumen.csv\", root_dir=dir_experimento):\n",
    "        with open(dir_experimento + \"resumen.csv\", \"w\") as resumen:        \n",
    "            print(\"Instancia\", \"Vértices\", \"Aristas\", \"Densidad\", \"Variables\", \n",
    "              \"Restricciones\", \"Estado\", \"LB\", \"UB\", \"Gap\", \"Tiempo\",\n",
    "              file=resumen, sep=',')\n",
    "    \n",
    "    # Recorremos las instancias\n",
    "    for ruta in sorted(glob.glob(\"*.graph\", root_dir=dir_instancias)):\n",
    "        # Nos quedamos con el nombre de la instancia sin el .graph\n",
    "        ruta = ruta[:-len(\".graph\")] \n",
    "        # Leemos la instancia\n",
    "        G, k, u = instancia.leer_instancia(dir_instancias + ruta) \n",
    "        # Creamos y abrimos el archivo para guardar el log de CPLEX\n",
    "        with open(dir_experimento + ruta + \".log\", \"w\") as log:\n",
    "            # Resolvemos\n",
    "             modelo, sol = resolver_PDG(G, k, u, log) \n",
    "\n",
    "        # Procesamos la solución\n",
    "        if sol: # Si encontró solución\n",
    "            # Recuperamos la función de dominación\n",
    "            f = obtener_func_dom(G, sol)\n",
    "            assert es_func_dom(G, k, u, f), \"Error: No es funcion de dominacion\"\n",
    "            # Escribimos la funcion de dominacion\n",
    "            instancia.escribir_diccionario(f, dir_experimento + ruta + \".sol\")\n",
    "            obj_value = modelo.objective_value\n",
    "        else: # Si no encontró solución\n",
    "            instancia.escribir_diccionario(dict(), dir_experimento + ruta + \".sol\")\n",
    "            obj_value = -1\n",
    "        \n",
    "        # Escribimos el resumen\n",
    "        with open(dir_experimento + \"resumen.csv\", \"a\") as resumen: \n",
    "            print(ruta, G.number_of_nodes(), G.number_of_edges(), nx.density(G),\n",
    "                  modelo.number_of_variables, modelo.number_of_constraints,\n",
    "                  modelo.solve_details.status, modelo.solve_details.best_bound, \n",
    "                  obj_value, modelo.solve_details.gap, \n",
    "                  modelo.solve_details.time, file=resumen, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e3c86",
   "metadata": {},
   "source": [
    "## Reanudación\n",
    "\n",
    "Lo último que vamos a cubrir en este notebook es la posibilidad de reanudar nuestras pruebas. Es muy habitual que mientras estemos corriendo un experimento, ocurra algún evento (e.g. un corte de luz) y la prueba se interrumpa. Es deseable poder reanudar el experimento desde el punto donde se interrumpió, sin perder todo el trabajo previo.\n",
    "\n",
    "Incluir este control es muy sencillo. Si recuerdan, cada vez que terminamos de resolver una instancia, escribimos algunos archivos de salida, en particular, el diccionario con la función de dominación. Por lo tanto, si este archivo ya existe, quiere decir que la instancia ya fue resuelta, y no hay necesidad de resolverla nuevamente.\n",
    "\n",
    "Podemos usar otra vez la función <code>glob</code> del módulo <code>glob</code> para buscar este archivo. De encontrarlo, entonces no seguimos procesando la instancia actual y continuamos con la siguiente; de lo contrario, seguimos resolviendo la instancia actual de la forma usual. Con esta incorporación, nuestro código queda reescrito como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_exp1(dir_instancias, dir_experimento):\n",
    "\n",
    "    # Si no existe el archivo de resumen, lo creamos y\n",
    "    # escribimos el nombre de las columnas\n",
    "    if not glob.glob(\"resumen.csv\", root_dir=dir_experimento):\n",
    "        with open(dir_experimento + \"resumen.csv\", \"w\") as resumen:        \n",
    "            print(\"Instancia\", \"Vértices\", \"Aristas\", \"Densidad\", \"Variables\", \n",
    "              \"Restricciones\", \"Estado\", \"LB\", \"UB\", \"Gap\", \"Tiempo\",\n",
    "              file=resumen, sep=',')\n",
    "    \n",
    "    # Recorremos las instancias\n",
    "    for ruta in sorted(glob.glob(\"*.graph\", root_dir=dir_instancias)):\n",
    "\n",
    "        # Nos quedamos con el nombre de la instancia sin el .graph\n",
    "        ruta = ruta[:-len(\".graph\")] \n",
    "\n",
    "        # Control de reanudación\n",
    "        if glob.glob(ruta + \".sol\", root_dir=dir_experimento):\n",
    "            continue\n",
    "\n",
    "        # Leemos la instancia\n",
    "        G, k, u = instancia.leer_instancia(dir_instancias + ruta) \n",
    "        # Creamos y abrimos el archivo para guardar el log de CPLEX\n",
    "        with open(dir_experimento + ruta + \".log\", \"w\") as log:\n",
    "            # Resolvemos\n",
    "             modelo, sol = resolver_PDG(G, k, u, log) \n",
    "\n",
    "        # Procesamos la solución\n",
    "        if sol: # Si encontró solución\n",
    "            # Recuperamos la función de dominación\n",
    "            f = obtener_func_dom(G, sol)\n",
    "            assert es_func_dom(G, k, u, f), \"Error: No es funcion de dominacion\"\n",
    "            # Escribimos la funcion de dominacion\n",
    "            instancia.escribir_diccionario(f, dir_experimento + ruta + \".sol\")\n",
    "            obj_value = modelo.objective_value\n",
    "        else: # Si no encontró solución\n",
    "            instancia.escribir_diccionario(dict(), dir_experimento + ruta + \".sol\")\n",
    "            obj_value = -1\n",
    "        \n",
    "        # Escribimos el resumen\n",
    "        with open(dir_experimento + \"resumen.csv\", \"a\") as resumen: \n",
    "            print(ruta, G.number_of_nodes(), G.number_of_edges(), nx.density(G),\n",
    "                  modelo.number_of_variables, modelo.number_of_constraints,\n",
    "                  modelo.solve_details.status, modelo.solve_details.best_bound, \n",
    "                  obj_value, modelo.solve_details.gap, \n",
    "                  modelo.solve_details.time, file=resumen, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566ba10",
   "metadata": {},
   "source": [
    "Volvamos entonces a ejecutar nuestro experimento computacional con todas las mejoras que agregamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutar_exp1(\"dataset/\", \"exp1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ae730",
   "metadata": {},
   "source": [
    "Nuevamente, podemos ir al directorio <code>exp1/</code> y ver las salidas generadas. O podemos abrir el resumen con una planilla de cálculo. También podemos ver el resumen desde acá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp1/resumen.csv\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4147ae",
   "metadata": {},
   "source": [
    "## Instancias infactibles\n",
    "\n",
    "Por último, vamos a mostrar que el código que desarrollamos también funciona en instancias infactibles.\n",
    "\n",
    "Agreguemos a nuestro dataset una instancia infactible (pensar por qué es infactible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4acdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(100)\n",
    "k = [4] * 100\n",
    "u = [1] * 100\n",
    "ruta = \"dataset/infactible\"\n",
    "instancia.escribir_instancia(G, k, u, ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b36f1",
   "metadata": {},
   "source": [
    "Y vamos a resolverla. Observar que, al llamar a <code>ejecutar_exp1</code>, solo vamos a resolver esta instancia, ya que todas las demás ya han sido resueltas y son detectadas por el control de reanudación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutar_exp1(\"dataset/\", \"exp1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b2101",
   "metadata": {},
   "source": [
    "La solución encontrada es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97028473",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp1/infactible.sol\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b359b7",
   "metadata": {},
   "source": [
    "Y la última fila del resumen es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exp1/resumen.csv\", \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    last_line = lines[-1]\n",
    "    print(last_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d803715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
